import { AudioFile, TranscriptionResult, SummaryResult, SpeakerSegment } from '@/types';
import { databaseService } from './database';
import { storageService } from './storage';
import { audioProcessingClient, ProcessingConfig } from './audioProcessingClient';
import { directApiProcessingService } from './directApiProcessing';

export interface ProcessingOptions {
  enableSpeakerSeparation?: boolean;
  maxSpeakers?: number;
  useUserEmbedding?: boolean;
  language?: string;
}

export interface ProcessingProgress {
  stage: 'preprocessing' | 'speaker_analysis' | 'chunk_processing' | 'transcribing' | 'integrating';
  progress: number;
  currentChunk?: number;
  totalChunks?: number;
  message?: string;
}

export class AudioProcessingService {
  private static instance: AudioProcessingService;

  static getInstance(): AudioProcessingService {
    if (!AudioProcessingService.instance) {
      AudioProcessingService.instance = new AudioProcessingService();
    }
    return AudioProcessingService.instance;
  }

  // ãƒ¡ã‚¤ãƒ³å‡¦ç†é–¢æ•°
  async processAudio(
    userId: string,
    audioId: string,
    options: ProcessingOptions = {},
    onProgress?: (progress: ProcessingProgress) => void
  ): Promise<AudioFile> {
    try {
      console.log('ğŸ¯ Starting audio processing for:', audioId);
      
      // å‡¦ç†é–‹å§‹æ™‚ã«ãƒ•ã‚¡ã‚¤ãƒ«çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆå†å‡¦ç†å¯¾å¿œï¼‰
      await databaseService.updateAudioFile(userId, audioId, {
        status: 'uploaded',
        processingProgress: 0,
        updatedAt: new Date()
      });
      console.log('ğŸ”„ File status reset for reprocessing');
      
      // æœ¬ç•ªå‡¦ç†ã‚’å®Ÿè¡Œï¼ˆãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰å‰Šé™¤ï¼‰
      console.log('ğŸ”§ Processing real audio for user:', userId);
      
      // APIè¨­å®šã‚’å–å¾—ã—ã¦å®Ÿéš›ã®å‡¦ç†ã‚’å®Ÿè¡Œ
      const apiConfig = await databaseService.getAPIConfig(userId);
      if (!apiConfig) {
        await databaseService.updateAudioFile(userId, audioId, {
          status: 'error',
          processingProgress: 0
        });
        throw new Error('APIè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è¨­å®šãƒšãƒ¼ã‚¸ã§APIè¨­å®šã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚');
      }
      
      console.log('ğŸ” Retrieved API config:', {
        speechProvider: apiConfig.speechProvider,
        speechApiKeyLength: apiConfig.speechApiKey?.length || 0,
        llmProvider: apiConfig.llmProvider,
        llmApiKeyLength: apiConfig.llmApiKey?.length || 0,
        allKeys: Object.keys(apiConfig)
      });
      
      // APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
      if (!apiConfig.speechApiKey || !apiConfig.llmApiKey) {
        await databaseService.updateAudioFile(userId, audioId, {
          status: 'error',
          processingProgress: 0
        });
        throw new Error('APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¨­å®šãƒšãƒ¼ã‚¸ã§éŸ³å£°èªè­˜APIã¨LLM APIã®è¨­å®šã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚');
      }
      
      console.log('ğŸ”‘ Using configured APIs:', {
        speechProvider: apiConfig.speechProvider,
        llmProvider: apiConfig.llmProvider
      });
      
      // Firebase Functionså‡¦ç†ã‚’å®Ÿè¡Œ
      try {
        console.log('ğŸš€ Attempting Firebase Functions processing...');
        return await this.processAudioWithFirebaseFunctions(userId, audioId, apiConfig, options, onProgress);
      } catch (functionsError) {
        console.error('âŒ Firebase Functions processing failed:', functionsError);
        
        // Firebase Functions ãŒå¤±æ•—ã—ãŸå ´åˆã¯ direct APIå‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        console.log('ğŸ”„ Falling back to direct API processing...');
        try {
          return await this.processAudioWithDirectAPI(userId, audioId, apiConfig, options, onProgress);
        } catch (directError) {
          console.error('âŒ Direct API processing also failed:', directError);
          
          await databaseService.updateAudioFile(userId, audioId, {
            status: 'error',
            processingProgress: 0
          });
          
          throw new Error(`éŸ³å£°å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n\nã€çŠ¶æ³ã€‘\nãƒ»Firebase Functions: ${functionsError.message}\nãƒ»Direct API: ${directError.message}\n\nã€å¯¾å¿œæ–¹æ³•ã€‘\n1. APIè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„\n2. APIã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„\n3. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„`)
        }
      }
      
    } catch (error) {
      console.error('Audio processing failed:', error);
      
      await databaseService.updateAudioFile(userId, audioId, {
        status: 'error',
        processingProgress: 0
      });

      throw error;
    }
  }

  // Firebase Functions ã‚’ä½¿ç”¨ã—ãŸå‡¦ç†
  private async processAudioWithFirebaseFunctions(
    userId: string,
    audioId: string,
    apiConfig: any,
    options: ProcessingOptions = {},
    onProgress?: (progress: ProcessingProgress) => void
  ): Promise<AudioFile> {
    console.log('ğŸ”„ Processing audio with Firebase Functions');
    
    try {
      onProgress?.({
        stage: 'preprocessing',
        progress: 10,
        message: 'Firebase Functions ã§å‡¦ç†ã‚’é–‹å§‹...'
      });

      // Firebase Functions ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
      const functionsUrl = 'https://us-central1-voicenote-dev.cloudfunctions.net/processAudio';
      const response = await fetch(functionsUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          user_id: userId,
          audio_id: audioId,
          config: {
            speech_provider: apiConfig.speechProvider,
            speech_api_key: apiConfig.speechApiKey,
            speech_model: apiConfig.speechModel,
            llm_provider: apiConfig.llmProvider,
            llm_api_key: apiConfig.llmApiKey,
            llm_model: apiConfig.llmModel
          }
        })
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        throw new Error(errorData.message || `HTTP ${response.status}: ${response.statusText}`);
      }

      const result = await response.json();
      console.log('ğŸ“¨ Firebase Functions response:', result);

      onProgress?.({
        stage: 'integrating',
        progress: 80,
        message: 'Firebase Functions å‡¦ç†å®Œäº†ã€çµæœã‚’å–å¾—ä¸­...'
      });

      // å‡¦ç†å®Œäº†ã¾ã§å¾…æ©Ÿ
      return await this.waitForCompletion(userId, audioId);

    } catch (error) {
      console.error('Firebase Functions processing failed:', error);
      throw error;
    }
  }

  // Direct API ã‚’ä½¿ç”¨ã—ãŸå‡¦ç†
  private async processAudioWithDirectAPI(
    userId: string,
    audioId: string,
    apiConfig: any,
    options: ProcessingOptions = {},
    onProgress?: (progress: ProcessingProgress) => void
  ): Promise<AudioFile> {
    console.log('ğŸ”„ Processing audio with Direct APIs');
    
    try {
      onProgress?.({
        stage: 'preprocessing',
        progress: 10,
        message: 'Direct API ã§å‡¦ç†ã‚’é–‹å§‹...'
      });

      // Direct API Processing Service ã‚’ä½¿ç”¨
      return await directApiProcessingService.processAudioDirect(
        userId,
        audioId,
        apiConfig,
        (progress, message) => {
          onProgress?.({
            stage: this.progressToStage(progress),
            progress,
            message
          });
        }
      );

    } catch (error) {
      console.error('Direct API processing failed:', error);
      throw error;
    }
  }

  // ãƒ‡ãƒ¢å‡¦ç†ï¼ˆå®Ÿéš›ã®æ–‡å­—èµ·ã“ã—ãƒ»è¦ç´„ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼‰
  private async processAudioDemo(
    userId: string,
    audioId: string,
    options: ProcessingOptions = {},
    onProgress?: (progress: ProcessingProgress) => void
  ): Promise<AudioFile> {
    console.log('ğŸ­ Starting demo audio processing for:', audioId);
    
    try {
      // Phase 1: å‰å‡¦ç†
      onProgress?.({
        stage: 'preprocessing',
        progress: 10,
        message: 'ãƒã‚¤ã‚ºé™¤å»å‡¦ç†ä¸­...'
      });
      
      await databaseService.updateAudioFile(userId, audioId, {
        status: 'preprocessing',
        processingProgress: 10
      });
      
      await new Promise(resolve => setTimeout(resolve, 1000));

      // Phase 2: è©±è€…åˆ†æ
      onProgress?.({
        stage: 'speaker_analysis',
        progress: 30,
        message: 'ã‚°ãƒ­ãƒ¼ãƒãƒ«è©±è€…åˆ†æä¸­...'
      });
      
      await databaseService.updateAudioFile(userId, audioId, {
        status: 'speaker_analysis',
        processingProgress: 30
      });
      
      await new Promise(resolve => setTimeout(resolve, 1500));

      // Phase 3: æ–‡å­—èµ·ã“ã—
      onProgress?.({
        stage: 'transcribing',
        progress: 60,
        message: 'éŸ³å£°èªè­˜å‡¦ç†ä¸­...'
      });
      
      await databaseService.updateAudioFile(userId, audioId, {
        status: 'transcribing',
        processingProgress: 60
      });
      
      await new Promise(resolve => setTimeout(resolve, 2000));

      // æ–‡å­—èµ·ã“ã—çµæœã‚’ç”Ÿæˆ
      const transcription = {
        text: 'ã“ã‚Œã¯éŸ³å£°æ–‡å­—èµ·ã“ã—çµæœã®ãƒ‡ãƒ¢ã§ã™ã€‚å®Ÿéš›ã®éŸ³å£°èªè­˜APIãŒçµ±åˆã•ã‚Œã‚‹ã¨ã€ã“ã“ã«æ­£ç¢ºãªæ–‡å­—èµ·ã“ã—çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚è©±è€…åˆ†é›¢ã«ã‚ˆã‚Šã€å„ç™ºè¨€è€…ã®ç™ºè¨€ã‚’æ˜ç¢ºã«åŒºåˆ¥ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚',
        segments: [
          {
            start: 0,
            end: 5,
            text: 'ã“ã‚“ã«ã¡ã¯ã€ä»Šæ—¥ã¯ãŠå¿™ã—ã„ä¸­ãŠæ™‚é–“ã‚’ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚',
            speaker: 'Aã•ã‚“',
            confidence: 0.95
          },
          {
            start: 5,
            end: 12,
            text: 'ã“ã¡ã‚‰ã“ãã€ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ã€‚æ—©é€Ÿã§ã™ãŒã€ä»Šå›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¤ã„ã¦èª¬æ˜ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚',
            speaker: 'Bã•ã‚“',
            confidence: 0.92
          },
          {
            start: 12,
            end: 18,
            text: 'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ¦‚è¦ã«ã¤ã„ã¦ã¯ç†è§£ã—ã¾ã—ãŸãŒã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã©ã®ã‚ˆã†ã«ãªã£ã¦ã„ã¾ã™ã§ã—ã‚‡ã†ã‹ï¼Ÿ',
            speaker: 'Cã•ã‚“',
            confidence: 0.88
          },
          {
            start: 18,
            end: 25,
            text: 'ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ã¤ã„ã¦ã¯ã€æ¥æœˆã®ç¬¬ä¸€é€±ã‹ã‚‰é–‹å§‹äºˆå®šã§ã™ã€‚è©³ç´°ãªã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’ãŠé€ã‚Šã—ã¾ã™ã€‚',
            speaker: 'Aã•ã‚“',
            confidence: 0.94
          }
        ],
        speakers: ['Aã•ã‚“', 'Bã•ã‚“', 'Cã•ã‚“'],
        language: 'ja',
        confidence: 0.92,
        processingTime: 3000,
        apiProvider: 'demo',
        model: 'whisper-demo'
      };

      // Phase 4: è¦ç´„ç”Ÿæˆ
      onProgress?.({
        stage: 'integrating',
        progress: 85,
        message: 'AIè¦ç´„ã‚’ç”Ÿæˆä¸­...'
      });
      
      await databaseService.updateAudioFile(userId, audioId, {
        status: 'integrating',
        processingProgress: 85,
        transcription
      });
      
      await new Promise(resolve => setTimeout(resolve, 1500));

      // è¦ç´„çµæœã‚’ç”Ÿæˆ
      const summary = {
        overall: 'ã“ã®ä¼šè­°ã§ã¯æ–°ã—ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã¤ã„ã¦è­°è«–ã•ã‚Œã€å…·ä½“çš„ãªé€²è¡Œè¨ˆç”»ã¨æ‹…å½“è€…ã®å½¹å‰²åˆ†æ‹…ãŒæ±ºå®šã•ã‚Œã¾ã—ãŸã€‚å‚åŠ è€…é–“ã§æ´»ç™ºãªæ„è¦‹äº¤æ›ãŒè¡Œã‚ã‚Œã€ä»Šå¾Œã®æ–¹å‘æ€§ã«ã¤ã„ã¦åˆæ„ã«è‡³ã‚Šã¾ã—ãŸã€‚',
        speakerSummaries: {
          'Aã•ã‚“': 'ä¼šè­°ã®å¸ä¼šã‚’å‹™ã‚ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ¦‚è¦èª¬æ˜ã¨é€²è¡Œç®¡ç†ã‚’è¡Œã£ãŸã€‚é‡è¦ãªæ±ºå®šäº‹é …ã«ã¤ã„ã¦ç¢ºèªã‚’å–ã‚ŠãªãŒã‚‰è­°è«–ã‚’é€²ã‚ãŸã€‚',
          'Bã•ã‚“': 'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è©³ç´°ãªæŠ€è¡“ä»•æ§˜ã«ã¤ã„ã¦èª¬æ˜ã—ã€å®Ÿè£…æ–¹æ³•ã«ã¤ã„ã¦å…·ä½“çš„ãªææ¡ˆã‚’è¡Œã£ãŸã€‚',
          'Cã•ã‚“': 'ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ã¤ã„ã¦è³ªå•ã‚’è¡Œã„ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å®Ÿç¾å¯èƒ½æ€§ã«ã¤ã„ã¦æ¤œè¨ã—ãŸã€‚'
        },
        keyPoints: [
          'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–‹å§‹æ—¥ã¯æ¥æœˆã®ç¬¬ä¸€é€±ã«è¨­å®š',
          'è©³ç´°ãªæŠ€è¡“ä»•æ§˜ã«ã¤ã„ã¦èª¬æ˜ãŒè¡Œã‚ã‚ŒãŸ',
          'ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è©³ç´°ãªã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã®å…±æœ‰ãŒç´„æŸã•ã‚ŒãŸ',
          'å„å‚åŠ è€…ã®å½¹å‰²ã¨è²¬ä»»ãŒæ˜ç¢ºåŒ–ã•ã‚ŒãŸ'
        ],
        actionItems: [
          'è©³ç´°ãªã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã®ä½œæˆã¨å…±æœ‰ï¼ˆAã•ã‚“æ‹…å½“ï¼‰',
          'æŠ€è¡“ä»•æ§˜æ›¸ã®æœ€çµ‚åŒ–ï¼ˆBã•ã‚“æ‹…å½“ï¼‰',
          'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨ˆç”»ã®è©³ç´°ç¢ºèªï¼ˆCã•ã‚“æ‹…å½“ï¼‰',
          'æ¬¡å›ä¼šè­°ã®æ—¥ç¨‹èª¿æ•´'
        ],
        topics: ['ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨ˆç”»', 'ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†', 'æŠ€è¡“ä»•æ§˜', 'å½¹å‰²åˆ†æ‹…'],
        apiProvider: 'demo',
        model: 'gpt-demo',
        generatedAt: new Date()
      };

      // Phase 5: å®Œäº†
      onProgress?.({
        stage: 'integrating',
        progress: 100,
        message: 'å‡¦ç†å®Œäº†'
      });

      // æœ€çµ‚çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
      await databaseService.updateAudioFile(userId, audioId, {
        status: 'completed',
        processingProgress: 100,
        transcription,
        summary,
        updatedAt: new Date()
      });

      // æ›´æ–°ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å–å¾—
      const updatedFile = await databaseService.getAudioFile(userId, audioId);
      if (!updatedFile) {
        throw new Error('Failed to retrieve updated audio file');
      }

      console.log('âœ… Demo audio processing completed for:', audioId);
      return updatedFile;

    } catch (error) {
      console.error('âŒ Demo audio processing failed:', error);
      
      await databaseService.updateAudioFile(userId, audioId, {
        status: 'error',
        processingProgress: 0
      });
      
      throw error;
    }
  }

  // é€²æ—ç›£è¦–ï¼ˆéåŒæœŸï¼‰
  private async monitorProgress(
    userId: string,
    audioId: string,
    onProgress: (progress: ProcessingProgress) => void
  ): Promise<void> {
    try {
      for await (const status of audioProcessingClient.monitorProcessingProgress(userId, audioId)) {
        const progress: ProcessingProgress = {
          stage: this.mapStatusToStage(status.status),
          progress: status.progress,
          message: status.message,
          currentChunk: status.currentChunk,
          totalChunks: status.totalChunks
        };
        
        onProgress(progress);

        if (status.status === 'completed' || status.status === 'error') {
          break;
        }
      }
    } catch (error) {
      console.error('Progress monitoring failed:', error);
    }
  }

  // å‡¦ç†å®Œäº†å¾…æ©Ÿ
  private async waitForCompletion(userId: string, audioId: string): Promise<AudioFile> {
    // Firestoreã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ã«ä¾å­˜
    // ã¾ãŸã¯å®šæœŸçš„ã«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
    let attempts = 0;
    const maxAttempts = 360; // 30åˆ†é–“ç›£è¦–ï¼ˆ5ç§’é–“éš”ï¼‰

    while (attempts < maxAttempts) {
      const audioFile = await databaseService.getAudioFile(userId, audioId);
      
      if (audioFile?.status === 'completed') {
        return audioFile;
      } else if (audioFile?.status === 'error') {
        throw new Error('Audio processing failed on server');
      }

      await new Promise(resolve => setTimeout(resolve, 5000)); // 5ç§’å¾…æ©Ÿ
      attempts++;
    }

    throw new Error('Audio processing timeout');
  }

  // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ã‚¹ãƒ†ãƒ¼ã‚¸ã«ãƒãƒƒãƒ”ãƒ³ã‚°
  private mapStatusToStage(status: string): ProcessingProgress['stage'] {
    const stageMap: Record<string, ProcessingProgress['stage']> = {
      'preprocessing': 'preprocessing',
      'speaker_analysis': 'speaker_analysis', 
      'chunk_processing': 'chunk_processing',
      'transcribing': 'transcribing',
      'integrating': 'integrating'
    };
    
    return stageMap[status] || 'preprocessing';
  }

  // é€²æ—ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã‚’ã‚¹ãƒ†ãƒ¼ã‚¸ã«ãƒãƒƒãƒ”ãƒ³ã‚°
  private progressToStage(progress: number): ProcessingProgress['stage'] {
    if (progress < 20) return 'preprocessing';
    if (progress < 40) return 'speaker_analysis';
    if (progress < 60) return 'transcribing';
    if (progress < 90) return 'integrating';
    return 'integrating';
  }

  // Phase 0: éŸ³å£°å‰å‡¦ç†
  private async preprocessAudio(
    userId: string,
    audioId: string,
    onProgress?: (progress: ProcessingProgress) => void
  ): Promise<void> {
    onProgress?.({
      stage: 'preprocessing',
      progress: 10,
      message: 'ãƒã‚¤ã‚ºé™¤å»å‡¦ç†ä¸­...'
    });

    // ãƒ¢ãƒƒã‚¯å‡¦ç†ï¼ˆå®Ÿéš›ã¯Pythonã‚µãƒ¼ãƒ“ã‚¹ã§å®Ÿè¡Œï¼‰
    await new Promise(resolve => setTimeout(resolve, 2000));

    onProgress?.({
      stage: 'preprocessing',
      progress: 20,
      message: 'éŸ³é‡æ­£è¦åŒ–ä¸­...'
    });

    await new Promise(resolve => setTimeout(resolve, 1000));

    // éŸ³å£°å“è³ªæƒ…å ±ã‚’æ›´æ–°
    await databaseService.updateAudioFile(userId, audioId, {
      audioQuality: {
        snr: 25.5, // Signal-to-Noise Ratio
        noiseLevel: 0.1,
        volumeLevel: 0.8,
        format: 'mp3',
        sampleRate: 44100,
        channels: 2
      }
    });
  }

  // Phase 1: è©±è€…åˆ†æ
  private async analyzeSpeakers(
    userId: string,
    audioId: string,
    options: ProcessingOptions,
    onProgress?: (progress: ProcessingProgress) => void
  ): Promise<{
    speakerCount: number;
    segments: SpeakerSegment[];
    globalSpeakers: any[];
  }> {
    await databaseService.updateAudioFile(userId, audioId, {
      status: 'speaker_analysis',
      processingProgress: 25
    });

    onProgress?.({
      stage: 'speaker_analysis',
      progress: 25,
      message: 'ã‚°ãƒ­ãƒ¼ãƒãƒ«è©±è€…åˆ†æä¸­...'
    });

    // ãƒ¢ãƒƒã‚¯è©±è€…åˆ†é›¢å‡¦ç†
    await new Promise(resolve => setTimeout(resolve, 3000));

    const mockSegments: SpeakerSegment[] = [
      { start: 0.0, end: 5.2, speaker: 'Speaker_0', confidence: 0.95 },
      { start: 5.2, end: 12.8, speaker: 'Speaker_1', confidence: 0.92 },
      { start: 12.8, end: 18.5, speaker: 'Speaker_0', confidence: 0.89 },
      { start: 18.5, end: 25.1, speaker: 'Speaker_2', confidence: 0.91 },
      { start: 25.1, end: 32.0, speaker: 'Speaker_1', confidence: 0.94 }
    ];

    // ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å­¦ç¿’éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯Aã•ã‚“ã€Bã•ã‚“ã®ãƒ©ãƒ™ãƒ«ã‚’ä½¿ç”¨
    const globalSpeakers = [
      { id: 'Speaker_0', name: 'Aã•ã‚“', embedding: [], confidence: 0.88 },
      { id: 'Speaker_1', name: 'Bã•ã‚“', embedding: [], confidence: 0.85 },
      { id: 'Speaker_2', name: 'Cã•ã‚“', embedding: [], confidence: 0.82 }
    ];

    onProgress?.({
      stage: 'speaker_analysis',
      progress: 40,
      message: `${globalSpeakers.length}åã®è©±è€…ã‚’æ¤œå‡ºã—ã¾ã—ãŸ`
    });

    return {
      speakerCount: globalSpeakers.length,
      segments: mockSegments,
      globalSpeakers
    };
  }

  // Phase 2: æ–‡å­—èµ·ã“ã—å‡¦ç†
  private async processTranscription(
    userId: string,
    audioId: string,
    speakerAnalysis: any,
    options: ProcessingOptions,
    onProgress?: (progress: ProcessingProgress) => void
  ): Promise<TranscriptionResult> {
    await databaseService.updateAudioFile(userId, audioId, {
      status: 'transcribing',
      processingProgress: 50
    });

    // é•·æ™‚é–“éŸ³å£°ã®å ´åˆã®ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    const shouldChunk = speakerAnalysis.segments.length > 20; // ä»®ã®æ¡ä»¶
    
    if (shouldChunk) {
      return await this.processWithChunks(userId, audioId, speakerAnalysis, options, onProgress);
    } else {
      return await this.processDirectTranscription(userId, audioId, speakerAnalysis, options, onProgress);
    }
  }

  // ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²å‡¦ç†
  private async processWithChunks(
    userId: string,
    audioId: string,
    speakerAnalysis: any,
    options: ProcessingOptions,
    onProgress?: (progress: ProcessingProgress) => void
  ): Promise<TranscriptionResult> {
    const totalChunks = 8; // 8æ™‚é–“éŸ³å£°ã‚’30åˆ†ãšã¤åˆ†å‰²
    
    await databaseService.updateAudioFile(userId, audioId, {
      status: 'chunk_processing',
      totalChunks,
      processedChunks: 0,
      processingProgress: 50
    });

    onProgress?.({
      stage: 'chunk_processing',
      progress: 50,
      currentChunk: 0,
      totalChunks,
      message: 'ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²å‡¦ç†ã‚’é–‹å§‹ã—ã¦ã„ã¾ã™...'
    });

    // å„ãƒãƒ£ãƒ³ã‚¯ã‚’é †æ¬¡å‡¦ç†
    const allSegments: any[] = [];
    
    for (let i = 0; i < totalChunks; i++) {
      onProgress?.({
        stage: 'chunk_processing',
        progress: 50 + (i / totalChunks) * 25,
        currentChunk: i + 1,
        totalChunks,
        message: `ãƒãƒ£ãƒ³ã‚¯ ${i + 1}/${totalChunks} ã‚’å‡¦ç†ä¸­...`
      });

      // ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
      await new Promise(resolve => setTimeout(resolve, 1500));

      // ãƒãƒ£ãƒ³ã‚¯çµæœã‚’ãƒãƒ¼ã‚¸
      const chunkSegments = speakerAnalysis.segments.slice(
        Math.floor(i * speakerAnalysis.segments.length / totalChunks),
        Math.floor((i + 1) * speakerAnalysis.segments.length / totalChunks)
      );

      allSegments.push(...chunkSegments);

      await databaseService.updateAudioFile(userId, audioId, {
        processedChunks: i + 1,
        processingProgress: 50 + ((i + 1) / totalChunks) * 25
      });
    }

    return this.createTranscriptionResult(allSegments, speakerAnalysis.globalSpeakers);
  }

  // ç›´æ¥æ–‡å­—èµ·ã“ã—å‡¦ç†
  private async processDirectTranscription(
    userId: string,
    audioId: string,
    speakerAnalysis: any,
    options: ProcessingOptions,
    onProgress?: (progress: ProcessingProgress) => void
  ): Promise<TranscriptionResult> {
    onProgress?.({
      stage: 'transcribing',
      progress: 60,
      message: 'éŸ³å£°èªè­˜å‡¦ç†ä¸­...'
    });

    // ãƒ¢ãƒƒã‚¯æ–‡å­—èµ·ã“ã—å‡¦ç†
    await new Promise(resolve => setTimeout(resolve, 4000));

    return this.createTranscriptionResult(speakerAnalysis.segments, speakerAnalysis.globalSpeakers);
  }

  // æ–‡å­—èµ·ã“ã—çµæœä½œæˆ
  private createTranscriptionResult(segments: SpeakerSegment[], globalSpeakers: any[]): TranscriptionResult {
    const mockText = `
ã“ã‚Œã¯ä¼šè­°ã®éŸ³å£°æ–‡å­—èµ·ã“ã—çµæœã®ã‚µãƒ³ãƒ—ãƒ«ã§ã™ã€‚å®Ÿéš›ã®éŸ³å£°èªè­˜APIãŒçµ±åˆã•ã‚Œã‚‹ã¨ã€
ã“ã“ã«æ­£ç¢ºãªæ–‡å­—èµ·ã“ã—çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚è©±è€…åˆ†é›¢ã«ã‚ˆã‚Šã€å„ç™ºè¨€è€…ã®ç™ºè¨€ã‚’
æ˜ç¢ºã«åŒºåˆ¥ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚8æ™‚é–“ã¾ã§ã®é•·æ™‚é–“éŸ³å£°ã«ã‚‚å¯¾å¿œã—ã¦ãŠã‚Šã€
é«˜ç²¾åº¦ãªå‡¦ç†ãŒå¯èƒ½ã§ã™ã€‚
    `.trim();

    const transcriptionSegments = segments.map((segment, index) => ({
      start: segment.start,
      end: segment.end,
      text: `ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ${index + 1}ã®æ–‡å­—èµ·ã“ã—å†…å®¹ã§ã™ã€‚${segment.speaker}ã®ç™ºè¨€ã€‚`,
      speaker: globalSpeakers.find(s => s.id === segment.speaker)?.name || segment.speaker,
      confidence: segment.confidence,
      words: []
    }));

    return {
      text: mockText,
      segments: transcriptionSegments,
      speakers: globalSpeakers.map(s => s.name),
      language: 'ja',
      confidence: 0.92,
      processingTime: 180,
      apiProvider: 'openai',
      model: 'whisper-1'
    };
  }

  // Phase 3: è¦ç´„ç”Ÿæˆ
  private async generateSummary(
    userId: string,
    audioId: string,
    transcription: TranscriptionResult,
    onProgress?: (progress: ProcessingProgress) => void
  ): Promise<SummaryResult> {
    await databaseService.updateAudioFile(userId, audioId, {
      status: 'integrating',
      processingProgress: 80
    });

    onProgress?.({
      stage: 'integrating',
      progress: 80,
      message: 'AIè¦ç´„ã‚’ç”Ÿæˆä¸­...'
    });

    // ãƒ¢ãƒƒã‚¯è¦ç´„ç”Ÿæˆ
    await new Promise(resolve => setTimeout(resolve, 3000));

    onProgress?.({
      stage: 'integrating',
      progress: 95,
      message: 'æœ€çµ‚çµ±åˆå‡¦ç†ä¸­...'
    });

    const mockSummary: SummaryResult = {
      overall: `
ã“ã®ä¼šè­°ã§ã¯ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®é€²æ—çŠ¶æ³ã¨ä»Šå¾Œã®è¨ˆç”»ã«ã¤ã„ã¦è©±ã—åˆã‚ã‚Œã¾ã—ãŸã€‚
ä¸»è¦ãªè­°é¡Œã¨ã—ã¦ã€é–‹ç™ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è¦‹ç›´ã—ã€ãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã€å“è³ªç®¡ç†ã«ã¤ã„ã¦
è­°è«–ã•ã‚Œã¾ã—ãŸã€‚å‚åŠ è€…å…¨å“¡ãŒå»ºè¨­çš„ãªæ„è¦‹äº¤æ›ã‚’è¡Œã„ã€å…·ä½“çš„ãªè¡Œå‹•è¨ˆç”»ãŒç­–å®šã•ã‚Œã¾ã—ãŸã€‚
      `.trim(),
      speakerSummaries: {
        'ã‚ãªãŸ': 'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å…¨ä½“é€²æ—ã«ã¤ã„ã¦å ±å‘Šã—ã€èª²é¡Œç‚¹ã‚’æ•´ç†ã—ã¦è§£æ±ºç­–ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚',
        'Aã•ã‚“': 'æŠ€è¡“çš„ãªè¦³ç‚¹ã‹ã‚‰è©³ç´°ãªåˆ†æã‚’æä¾›ã—ã€å®Ÿè£…æ–¹é‡ã«ã¤ã„ã¦å…·ä½“çš„ãªææ¡ˆã‚’è¡Œã„ã¾ã—ãŸã€‚',
        'Bã•ã‚“': 'ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†ã¨ãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã«ã¤ã„ã¦å°‚é–€çš„ãªè¦‹è§£ã‚’ç¤ºã—ã€æœ€é©åŒ–æ¡ˆã‚’æç¤ºã—ã¾ã—ãŸã€‚'
      },
      keyPoints: [
        'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®é€²æ—ã¯æ¦‚ã­é †èª¿ã§ã€äºˆå®šã®80%ãŒå®Œäº†',
        'å“è³ªå‘ä¸Šã®ãŸã‚ã®æ–°ã—ã„ãƒ†ã‚¹ãƒˆæ‰‹æ³•ã®å°å…¥ã‚’æ±ºå®š',
        'ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³ã®è§£æ±ºã®ãŸã‚ã€è¿½åŠ ãƒ¡ãƒ³ãƒãƒ¼ã®æ¡ç”¨ã‚’æ¤œè¨',
        'æ¬¡å›ãƒªãƒªãƒ¼ã‚¹ã®æ—¥ç¨‹ã‚’2é€±é–“å¾Œã‚å€’ã—ã™ã‚‹ã“ã¨ã§åˆæ„'
      ],
      actionItems: [
        'æ–°ã—ã„ãƒ†ã‚¹ãƒˆæ‰‹æ³•ã®è©³ç´°ä»•æ§˜æ›¸ä½œæˆï¼ˆæ‹…å½“ï¼šAã•ã‚“ã€æœŸé™ï¼šæ¥é€±é‡‘æ›œï¼‰',
        'æ¡ç”¨è¨ˆç”»ã®ä½œæˆã¨æ‰¿èªå–å¾—ï¼ˆæ‹…å½“ï¼šBã•ã‚“ã€æœŸé™ï¼šä»Šæœˆæœ«ï¼‰',
        'ãƒªãƒªãƒ¼ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®é–¢ä¿‚éƒ¨ç½²ã¸ã®é€šçŸ¥ï¼ˆæ‹…å½“ï¼šã‚ãªãŸã€æœŸé™ï¼šæ˜æ—¥ï¼‰',
        'æ¬¡å›ä¼šè­°ã®æ—¥ç¨‹èª¿æ•´ï¼ˆæ‹…å½“ï¼šã‚ãªãŸã€æœŸé™ï¼šä»Šé€±ä¸­ï¼‰'
      ],
      topics: [
        'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé€²æ—å ±å‘Š',
        'å“è³ªç®¡ç†æ‰‹æ³•ã®æ”¹å–„',
        'ãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã®æœ€é©åŒ–',
        'ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«èª¿æ•´',
        'æ¬¡å›ãƒªãƒªãƒ¼ã‚¹è¨ˆç”»'
      ],
      apiProvider: 'openai',
      model: 'gpt-4',
      generatedAt: new Date()
    };

    return mockSummary;
  }

  // å‡¦ç†çŠ¶æ³ã®å–å¾—
  async getProcessingStatus(userId: string, audioId: string): Promise<{
    status: AudioFile['status'];
    progress: number;
    currentChunk?: number;
    totalChunks?: number;
  } | null> {
    try {
      const audioFile = await databaseService.getAudioFile(userId, audioId);
      if (!audioFile) return null;

      return {
        status: audioFile.status,
        progress: audioFile.processingProgress || 0,
        currentChunk: audioFile.processedChunks,
        totalChunks: audioFile.totalChunks
      };
    } catch (error) {
      console.error('Failed to get processing status:', error);
      return null;
    }
  }

  // å‡¦ç†ã®ã‚­ãƒ£ãƒ³ã‚»ãƒ«
  async cancelProcessing(userId: string, audioId: string): Promise<void> {
    try {
      await databaseService.updateAudioFile(userId, audioId, {
        status: 'error',
        processingProgress: 0
      });

      // é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
      await storageService.deleteAudioFiles(userId, audioId);
    } catch (error) {
      console.error('Failed to cancel processing:', error);
      throw error;
    }
  }
}

export const audioProcessingService = AudioProcessingService.getInstance();