import { ChatMessage, AudioFile } from '@/types';
import { isDemoMode } from '@/lib/firebase';

export interface AskAIRequest {
  audioId: string;
  question: string;
  context?: string;
}

export interface AskAIResponse {
  answer: string;
  sources?: string[];
  confidence?: number;
}

export class LLMService {
  private static instance: LLMService;

  static getInstance(): LLMService {
    if (!LLMService.instance) {
      LLMService.instance = new LLMService();
    }
    return LLMService.instance;
  }

  // Ask AIæ©Ÿèƒ½ - éŸ³å£°ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«é–¢ã™ã‚‹è³ªå•å¿œç­”
  async askAI(
    userId: string,
    audioFile: AudioFile,
    question: string
  ): Promise<AskAIResponse> {
    try {
      // ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ç”¨ã®å‡¦ç†
      if (isDemoMode || userId === 'demo-user-123') {
        console.log('ğŸ­ LLM: Demo mode Ask AI simulation');
        
        // ãƒ‡ãƒ¢ç”¨ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ
        const demoAnswer = this.generateDemoAnswer(question, audioFile);
        
        // ãƒªã‚¢ãƒ«ãªé…å»¶ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        await new Promise(resolve => setTimeout(resolve, 1000 + Math.random() * 2000));
        
        return {
          answer: demoAnswer,
          sources: ['æ–‡å­—èµ·ã“ã—çµæœ', 'è¦ç´„å†…å®¹'],
          confidence: 0.85
        };
      }

      // å®Ÿéš›ã®LLM APIå‘¼ã³å‡ºã—ï¼ˆå®Ÿè£…æ™‚ã«è¿½åŠ ï¼‰
      const context = this.buildContext(audioFile);
      const response = await this.callLLMAPI(question, context);
      
      return response;
    } catch (error) {
      console.error('Ask AI failed:', error);
      throw new Error('AIå¿œç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ');
    }
  }

  // éŸ³å£°å†…å®¹ã‹ã‚‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
  private buildContext(audioFile: AudioFile): string {
    let context = '';
    
    // æ–‡å­—èµ·ã“ã—çµæœã‚’è¿½åŠ 
    if (audioFile.transcription) {
      context += `## æ–‡å­—èµ·ã“ã—çµæœ\n${audioFile.transcription.text}\n\n`;
      
      if (audioFile.transcription.segments && audioFile.transcription.segments.length > 0) {
        context += `## è©±è€…åˆ¥ç™ºè¨€å†…å®¹\n`;
        audioFile.transcription.segments.forEach((segment, index) => {
          context += `${segment.speaker}: ${segment.text}\n`;
        });
        context += '\n';
      }
    }
    
    // è¦ç´„ã‚’è¿½åŠ 
    if (audioFile.summary) {
      context += `## å…¨ä½“è¦ç´„\n${audioFile.summary.overall}\n\n`;
      
      if (audioFile.summary.keyPoints && audioFile.summary.keyPoints.length > 0) {
        context += `## é‡è¦ãƒã‚¤ãƒ³ãƒˆ\n`;
        audioFile.summary.keyPoints.forEach((point, index) => {
          context += `${index + 1}. ${point}\n`;
        });
        context += '\n';
      }
      
      if (audioFile.summary.actionItems && audioFile.summary.actionItems.length > 0) {
        context += `## ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ \n`;
        audioFile.summary.actionItems.forEach((item, index) => {
          context += `${index + 1}. ${item}\n`;
        });
        context += '\n';
      }
    }
    
    return context;
  }

  // å®Ÿéš›ã®LLM APIå‘¼ã³å‡ºã—ï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ï¼‰
  private async callLLMAPI(question: string, context: string): Promise<AskAIResponse> {
    // TODO: å®Ÿéš›ã®LLM APIï¼ˆOpenAI, Anthropic, Googleç­‰ï¼‰ã¨ã®çµ±åˆ
    console.log('ğŸ¤– LLM API call:', { question, contextLength: context.length });
    
    // ç¾åœ¨ã¯ãƒ€ãƒŸãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    await new Promise(resolve => setTimeout(resolve, 2000));
    
    return {
      answer: 'ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨LLM APIãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚APIè¨­å®šãƒšãƒ¼ã‚¸ã§LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã¨APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚',
      confidence: 0.0
    };
  }

  // ãƒ‡ãƒ¢ç”¨ã®å›ç­”ç”Ÿæˆ
  private generateDemoAnswer(question: string, audioFile: AudioFile): string {
    const lowerQuestion = question.toLowerCase();
    
    // è³ªå•ã®å†…å®¹ã«å¿œã˜ã¦ãƒ‡ãƒ¢å›ç­”ã‚’ç”Ÿæˆ
    if (lowerQuestion.includes('æ±ºå®š') || lowerQuestion.includes('æ±ºã¾ã£ãŸ')) {
      return `ã“ã®ä¼šè­°ã§ã¯ä»¥ä¸‹ã®é‡è¦ãªæ±ºå®šãŒãªã•ã‚Œã¾ã—ãŸï¼š

1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–‹å§‹æ—¥ã‚’æ¥æœˆç¬¬ä¸€é€±ã«è¨­å®š
2. äºˆç®—ã‚’å‰å›ææ¡ˆã‹ã‚‰20%å‰Šæ¸›ã™ã‚‹ã“ã¨ã§åˆæ„
3. é–‹ç™ºãƒãƒ¼ãƒ 5åä½“åˆ¶ã§é€²è¡Œã™ã‚‹ã“ã¨ã‚’æ±ºå®š
4. æ¬¡å›ãƒªãƒªãƒ¼ã‚¹ã®æ—¥ç¨‹ã‚’2é€±é–“å¾Œã‚å€’ã—ã™ã‚‹ã“ã¨ã§åˆæ„

ã“ã‚Œã‚‰ã®æ±ºå®šã¯å‚åŠ è€…å…¨å“¡ã®åˆæ„ã«ã‚ˆã‚Šæ±ºå®šã•ã‚Œã¾ã—ãŸã€‚`;
    }
    
    if (lowerQuestion.includes('é‡è¦') || lowerQuestion.includes('ãƒã‚¤ãƒ³ãƒˆ')) {
      return `ã“ã®éŸ³å£°ã®é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼š

â€¢ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®é€²æ—ã¯æ¦‚ã­é †èª¿ã§ã€äºˆå®šã®80%ãŒå®Œäº†
â€¢ å“è³ªå‘ä¸Šã®ãŸã‚ã®æ–°ã—ã„ãƒ†ã‚¹ãƒˆæ‰‹æ³•ã®å°å…¥ã‚’æ±ºå®š
â€¢ ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³ã®è§£æ±ºã®ãŸã‚ã€è¿½åŠ ãƒ¡ãƒ³ãƒãƒ¼ã®æ¡ç”¨ã‚’æ¤œè¨
â€¢ ãƒãƒ¼ãƒ é–“ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ”¹å–„ãŒå¿…è¦

ç‰¹ã«å“è³ªç®¡ç†ã®å¼·åŒ–ãŒä»Šå¾Œã®é‡è¦èª²é¡Œã¨ã—ã¦æŒ™ã’ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚`;
    }
    
    if (lowerQuestion.includes('ã‚¢ã‚¯ã‚·ãƒ§ãƒ³') || lowerQuestion.includes('ã‚¿ã‚¹ã‚¯') || lowerQuestion.includes('ã‚„ã‚‹ã“ã¨')) {
      return `ä»¥ä¸‹ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ãŒæ±ºå®šã•ã‚Œã¾ã—ãŸï¼š

ğŸ“‹ **å³åº§ã«å®Ÿè¡Œ**
â€¢ æ–°ã—ã„ãƒ†ã‚¹ãƒˆæ‰‹æ³•ã®è©³ç´°ä»•æ§˜æ›¸ä½œæˆï¼ˆAã•ã‚“æ‹…å½“ã€æœŸé™ï¼šæ¥é€±é‡‘æ›œï¼‰
â€¢ ãƒªãƒªãƒ¼ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®é–¢ä¿‚éƒ¨ç½²ã¸ã®é€šçŸ¥ï¼ˆã‚ãªãŸæ‹…å½“ã€æœŸé™ï¼šæ˜æ—¥ï¼‰

ğŸ“‹ **ä»Šæœˆä¸­**
â€¢ æ¡ç”¨è¨ˆç”»ã®ä½œæˆã¨æ‰¿èªå–å¾—ï¼ˆBã•ã‚“æ‹…å½“ã€æœŸé™ï¼šä»Šæœˆæœ«ï¼‰
â€¢ æ¬¡å›ä¼šè­°ã®æ—¥ç¨‹èª¿æ•´ï¼ˆã‚ãªãŸæ‹…å½“ã€æœŸé™ï¼šä»Šé€±ä¸­ï¼‰

å„æ‹…å½“è€…ã¯æœŸé™ã‚’å®ˆã£ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚`;
    }
    
    if (lowerQuestion.includes('èª°') || lowerQuestion.includes('ã ã‚Œ') || lowerQuestion.includes('è©±è€…')) {
      const speakers = audioFile.transcription?.speakers || ['ã‚ãªãŸ', 'Aã•ã‚“', 'Bã•ã‚“'];
      return `ã“ã®éŸ³å£°ã«ã¯${speakers.length}åã®è©±è€…ãŒå‚åŠ ã—ã¦ã„ã¾ã™ï¼š

${speakers.map((speaker, index) => 
  `**${speaker}**: ${this.getSpeakerDescription(speaker)}`
).join('\n')}

è©±è€…åˆ†é›¢ã«ã‚ˆã‚Šã€å„å‚åŠ è€…ã®ç™ºè¨€ã‚’æ˜ç¢ºã«åŒºåˆ¥ã§ãã¦ã„ã¾ã™ã€‚`;
    }
    
    // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å›ç­”
    return `ã”è³ªå•ã€Œ${question}ã€ã«ã¤ã„ã¦ãŠç­”ãˆã—ã¾ã™ã€‚

ã“ã®éŸ³å£°ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆ${audioFile.fileName}ï¼‰ã‚’åˆ†æã—ãŸçµæœã€ä»¥ä¸‹ã®æƒ…å ±ã‚’ãŠä¼ãˆã§ãã¾ã™ï¼š

â€¢ éŸ³å£°æ™‚é–“: ${Math.floor(audioFile.duration / 60)}åˆ†${audioFile.duration % 60}ç§’
â€¢ è©±è€…æ•°: ${audioFile.transcription?.speakers?.length || 3}å
â€¢ å‡¦ç†çŠ¶æ³: ${audioFile.status === 'completed' ? 'å®Œäº†' : 'å‡¦ç†ä¸­'}

ã‚ˆã‚Šå…·ä½“çš„ãªè³ªå•ã‚’ã„ãŸã ã‘ã‚Œã°ã€è©³ç´°ãªæƒ…å ±ã‚’ãŠç­”ãˆã§ãã¾ã™ã€‚ä¾‹ãˆã°ï¼š
- ã€Œã“ã®ä¼šè­°ã®æ±ºå®šäº‹é …ã¯ï¼Ÿã€
- ã€Œé‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’æ•™ãˆã¦ã€
- ã€Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã¯ï¼Ÿã€`;
  }

  // è©±è€…ã®èª¬æ˜ã‚’ç”Ÿæˆ
  private getSpeakerDescription(speaker: string): string {
    const descriptions: Record<string, string> = {
      'ã‚ãªãŸ': 'ä¼šè­°ã®å¸ä¼šè€…ã¨ã—ã¦é€²è¡Œç®¡ç†ã¨å…¨ä½“èª¿æ•´ã‚’æ‹…å½“',
      'Aã•ã‚“': 'æŠ€è¡“é¢ã®ãƒªãƒ¼ãƒ‰ã¨ã—ã¦å°‚é–€çš„ãªåˆ†æã¨ææ¡ˆã‚’å®Ÿæ–½',
      'Bã•ã‚“': 'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã®è¦³ç‚¹ã‹ã‚‰ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†ã‚’æ‹…å½“',
      'Cã•ã‚“': 'ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°è¦–ç‚¹ã‹ã‚‰ã®è¦æ±‚åˆ†æã¨å¸‚å ´å‹•å‘ã®å ±å‘Šã‚’æ‹…å½“',
      'Dã•ã‚“': 'å“è³ªä¿è¨¼ã®å°‚é–€å®¶ã¨ã—ã¦è£½å“å“è³ªã¨ãƒ†ã‚¹ãƒˆæˆ¦ç•¥ã‚’æ‹…å½“'
    };
    
    return descriptions[speaker] || 'é‡è¦ãªæ„è¦‹ã¨å»ºè¨­çš„ãªææ¡ˆã‚’æä¾›';
  }

  // ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ä½¿ç”¨ã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»˜ãå¿œç­”
  async askAIWithHistory(
    userId: string,
    audioFile: AudioFile,
    question: string,
    chatHistory: ChatMessage[]
  ): Promise<AskAIResponse> {
    try {
      // ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ç”¨ã®å‡¦ç†
      if (isDemoMode || userId === 'demo-user-123') {
        console.log('ğŸ­ LLM: Demo mode Ask AI with history');
        
        const response = await this.askAI(userId, audioFile, question);
        
        // å±¥æ­´ã‚’è€ƒæ…®ã—ãŸå›ç­”ã®èª¿æ•´
        if (chatHistory.length > 0) {
          const lastQuestion = chatHistory[chatHistory.length - 1]?.content;
          if (lastQuestion && question.includes('è©³ã—ã') || question.includes('ã‚‚ã†å°‘ã—')) {
            response.answer = `å…ˆã»ã©ã®è³ªå•ã€Œ${lastQuestion}ã€ã«é–¢é€£ã—ã¦ã€ã•ã‚‰ã«è©³ã—ããŠç­”ãˆã—ã¾ã™ã€‚\n\n${response.answer}`;
          }
        }
        
        return response;
      }

      // å®Ÿéš›ã®å®Ÿè£…ã§ã¯ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚‚å«ã‚ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
      const context = this.buildContextWithHistory(audioFile, chatHistory);
      const response = await this.callLLMAPI(question, context);
      
      return response;
    } catch (error) {
      console.error('Ask AI with history failed:', error);
      throw new Error('AIå¿œç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ');
    }
  }

  // ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’å«ã‚€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
  private buildContextWithHistory(audioFile: AudioFile, chatHistory: ChatMessage[]): string {
    let context = this.buildContext(audioFile);
    
    if (chatHistory.length > 0) {
      context += `## éå»ã®è³ªå•ã¨å›ç­”\n`;
      chatHistory.slice(-5).forEach((message, index) => { // ç›´è¿‘5ä»¶ã®ã¿
        context += `${message.role === 'user' ? 'Q' : 'A'}: ${message.content}\n`;
      });
      context += '\n';
    }
    
    return context;
  }
}

export const llmService = LLMService.getInstance();