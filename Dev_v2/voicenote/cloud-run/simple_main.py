import os
import logging
import base64
import tempfile
from typing import Dict, Any, Optional
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

# éŸ³å£°å‡¦ç†
import openai
from google.cloud import firestore, storage

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Firebase ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ï¼ˆèªè¨¼ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
db = None
storage_client = None
try:
    if os.getenv('GOOGLE_APPLICATION_CREDENTIALS') or os.getenv('GOOGLE_CLOUD_PROJECT'):
        db = firestore.Client()
        storage_client = storage.Client()
        logger.info("âœ… Firebase clients initialized")
    else:
        logger.info("ðŸ“ Firebase clients not initialized (running in demo mode)")
except Exception as e:
    logger.warning(f"âš ï¸ Firebase initialization failed (demo mode): {e}")
    db = None
    storage_client = None

# FastAPI ã‚¢ãƒ—ãƒªä½œæˆ
app = FastAPI(
    title="VoiceNote Simple Audio Processing",
    description="ç°¡æ˜“éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚µãƒ¼ãƒ“ã‚¹",
    version="1.0.0"
)

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«
class ProcessAudioRequest(BaseModel):
    user_id: str
    audio_id: str
    config: Dict[str, Any] = {}

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
@app.get("/health")
async def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {
        "status": "healthy",
        "service": "voicenote-simple-processor",
        "version": "1.0.0",
        "firebase": "available" if db else "unavailable",
        "endpoints": ["/health", "/process-audio", "/test-whisper"]
    }

# ãƒ†ã‚¹ãƒˆç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.post("/test-whisper")
async def test_whisper_endpoint(request: dict):
    """Whisper APIãƒ†ã‚¹ãƒˆç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        api_key = request.get('api_key', '')
        test_text = request.get('test_text', 'ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆéŸ³å£°ã§ã™ã€‚')
        
        if not api_key:
            raise HTTPException(status_code=400, detail="APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™")
        
        # OpenAI APIã‚­ãƒ¼ã®ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆãƒã‚§ãƒƒã‚¯
        if not api_key.startswith('sk-'):
            raise HTTPException(status_code=400, detail="ç„¡åŠ¹ãªAPIã‚­ãƒ¼å½¢å¼ã§ã™")
        
        # ãƒ†ã‚¹ãƒˆçµæžœã‚’è¿”ã™ï¼ˆå®Ÿéš›ã®APIã¯å‘¼ã°ãªã„ï¼‰
        return {
            "status": "success",
            "message": "APIã‚­ãƒ¼å½¢å¼ã¯æ­£å¸¸ã§ã™",
            "api_key_format": "valid",
            "test_mode": True,
            "mock_result": {
                "text": test_text,
                "language": "ja",
                "confidence": 0.95
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Test endpoint failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# éŸ³å£°å‡¦ç†é–‹å§‹
@app.post("/process-audio")
async def process_audio(request: ProcessAudioRequest):
    """éŸ³å£°å‡¦ç†é–‹å§‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        logger.info(f"Starting simple audio processing for user {request.user_id}, audio {request.audio_id}")
        
        # APIã‚­ãƒ¼ã®ç¢ºèª
        speech_api_key = request.config.get('speech_api_key', '')
        if not speech_api_key:
            raise HTTPException(status_code=400, detail="éŸ³å£°èªè­˜APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š
        openai.api_key = speech_api_key
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Firebase Storageã‹ã‚‰å–å¾—
        audio_url = await get_audio_file_url(request.user_id, request.audio_id)
        if not audio_url:
            raise HTTPException(status_code=404, detail="éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        audio_file_path = await download_audio_file(audio_url)
        
        # OpenAI Whisperã§æ–‡å­—èµ·ã“ã—
        transcript_result = await transcribe_with_whisper(audio_file_path, speech_api_key)
        
        # çµæžœã‚’Firestoreã«ä¿å­˜
        await save_transcription_result(request.user_id, request.audio_id, transcript_result)
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        os.unlink(audio_file_path)
        
        return {
            "status": "completed",
            "message": f"éŸ³å£°å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ: {request.audio_id}",
            "user_id": request.user_id,
            "audio_id": request.audio_id,
            "result": transcript_result
        }
        
    except Exception as e:
        logger.error(f"Failed to process audio: {e}")
        
        # ã‚¨ãƒ©ãƒ¼ã‚’Firestoreã«è¨˜éŒ²
        if db:
            try:
                await update_audio_status(request.user_id, request.audio_id, "error", 0, {"error": str(e)})
            except:
                pass
        
        raise HTTPException(status_code=500, detail=str(e))

async def get_audio_file_url(user_id: str, audio_id: str) -> Optional[str]:
    """Firestoreã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®URLã‚’å–å¾—"""
    try:
        if not db:
            # ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼šãƒ€ãƒŸãƒ¼URLã‚’è¿”ã™
            logger.info(f"Demo mode: returning mock URL for {user_id}/{audio_id}")
            return "https://sample-audio-files.s3.amazonaws.com/test.mp3"
            
        doc_ref = db.collection('audios').document(user_id).collection('files').document(audio_id)
        doc = doc_ref.get()
        
        if doc.exists:
            data = doc.to_dict()
            return data.get('fileUrl')
        
        return None
        
    except Exception as e:
        logger.error(f"Failed to get audio file URL: {e}")
        return None

async def download_audio_file(audio_url: str) -> str:
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    import httpx
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
    temp_file_path = temp_file.name
    temp_file.close()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    async with httpx.AsyncClient() as client:
        response = await client.get(audio_url)
        response.raise_for_status()
        
        with open(temp_file_path, 'wb') as f:
            f.write(response.content)
    
    return temp_file_path

async def transcribe_with_whisper(audio_file_path: str, api_key: str) -> Dict[str, Any]:
    """OpenAI Whisperã§éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—"""
    try:
        # OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š
        client = openai.OpenAI(api_key=api_key)
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã„ã¦æ–‡å­—èµ·ã“ã—
        with open(audio_file_path, 'rb') as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="ja",
                response_format="verbose_json"
            )
        
        # çµæžœã‚’æ•´å½¢
        result = {
            "text": transcript.text,
            "language": transcript.language if hasattr(transcript, 'language') else 'ja',
            "duration": transcript.duration if hasattr(transcript, 'duration') else 0,
            "segments": transcript.segments if hasattr(transcript, 'segments') else [],
            "provider": "openai",
            "model": "whisper-1"
        }
        
        # ç°¡æ˜“çš„ãªè©±è€…åˆ†é›¢ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯pyannote.audioã‚’ä½¿ç”¨ï¼‰
        segments = []
        if hasattr(transcript, 'segments') and transcript.segments:
            for i, segment in enumerate(transcript.segments):
                segments.append({
                    "id": i,
                    "start": segment.start,
                    "end": segment.end,
                    "text": segment.text,
                    "speaker": "ã‚ãªãŸ" if i % 2 == 0 else "Aã•ã‚“",  # äº¤äº’ã«è©±è€…ã‚’å‰²ã‚Šå½“ã¦ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
                    "confidence": 0.9
                })
        else:
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ãŒãªã„å ´åˆã¯å…¨ä½“ã‚’1ã¤ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã—ã¦æ‰±ã†
            segments.append({
                "id": 0,
                "start": 0,
                "end": result["duration"],
                "text": result["text"],
                "speaker": "ã‚ãªãŸ",
                "confidence": 0.9
            })
        
        result["segments"] = segments
        
        # ç°¡æ˜“è¦ç´„ç”Ÿæˆï¼ˆå®Ÿéš›ã®LLM APIã‚’ä½¿ç”¨ã™ã‚‹å ´åˆï¼‰
        result["summary"] = {
            "overall": f"éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ç·æ–‡å­—æ•°: {len(result['text'])}æ–‡å­—",
            "speakers": {
                "ã‚ãªãŸ": "ä¸»ãªç™ºè¨€è€…ã¨ã—ã¦ä¼šè©±ã«å‚åŠ ",
                "Aã•ã‚“": "å¯¾è©±ç›¸æ‰‹ã¨ã—ã¦ä¼šè©±ã«å‚åŠ "
            },
            "topics": ["ä¼šè©±", "éŸ³å£°èªè­˜", "æ–‡å­—èµ·ã“ã—"]
        }
        
        return result
        
    except Exception as e:
        logger.error(f"Whisper transcription failed: {e}")
        raise Exception(f"éŸ³å£°æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")

async def save_transcription_result(user_id: str, audio_id: str, result: Dict[str, Any]):
    """æ–‡å­—èµ·ã“ã—çµæžœã‚’Firestoreã«ä¿å­˜"""
    try:
        if not db:
            logger.info(f"Demo mode: would save transcription for {user_id}/{audio_id}")
            logger.info(f"Result preview: {result.get('text', '')[:100]}...")
            return
            
        doc_ref = db.collection('audios').document(user_id).collection('files').document(audio_id)
        
        update_data = {
            'status': 'completed',
            'processingProgress': 100,
            'transcription': result,
            'summary': result.get('summary', {}),
            'updatedAt': firestore.SERVER_TIMESTAMP
        }
        
        doc_ref.update(update_data)
        logger.info(f"Transcription result saved for {user_id}/{audio_id}")
        
    except Exception as e:
        logger.error(f"Failed to save transcription result: {e}")
        raise

async def update_audio_status(user_id: str, audio_id: str, status: str, 
                            progress: int, additional_data: Dict[str, Any] = None):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®çŠ¶æ…‹æ›´æ–°"""
    try:
        if not db:
            logger.info(f"Demo mode: would update status {user_id}/{audio_id} -> {status} ({progress}%)")
            return
            
        doc_ref = db.collection('audios').document(user_id).collection('files').document(audio_id)
        
        update_data = {
            'status': status,
            'processingProgress': progress,
            'updatedAt': firestore.SERVER_TIMESTAMP
        }
        
        if additional_data:
            update_data.update(additional_data)
        
        doc_ref.update(update_data)
        
    except Exception as e:
        logger.error(f"Failed to update audio status: {e}")

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8080))
    
    uvicorn.run(
        "simple_main:app",
        host="0.0.0.0",
        port=port,
        log_level="info"
    )