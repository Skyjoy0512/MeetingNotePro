const { chromium } = require('playwright');

async function uploadAndTestRealProcessing() {
  console.log('ğŸ¯ Upload and Test Real Processing with axios');
  console.log('==============================================');

  const browser = await chromium.launch({ headless: false });
  const context = await browser.newContext();
  const page = await context.newPage();

  // Capture detailed processing logs
  page.on('console', msg => {
    const type = msg.type();
    const text = msg.text();
    
    console.log(`ğŸ“± Console [${type.toUpperCase()}]: ${text}`);
  });

  // Monitor Firebase Functions calls
  page.on('response', response => {
    const url = response.url();
    const status = response.status();
    
    if (url.includes('cloudfunctions.net') || url.includes('run.app')) {
      console.log(`ğŸ”¥ Firebase Functions: ${status} - ${url}`);
    }
    
    if (url.includes('openai.com')) {
      console.log(`ğŸ¤– OpenAI API: ${status} - ${url}`);
    }
    
    if (!response.ok() && status >= 400) {
      console.log(`âŒ HTTP Error: ${status} - ${url}`);
    }
  });

  try {
    console.log('ğŸŒ 1. Navigating to VoiceNote...');
    await page.goto('https://voicenote-dev.web.app', { waitUntil: 'networkidle' });
    await page.waitForTimeout(3000);

    // Sign in
    console.log('ğŸ” 2. Signing in...');
    await page.fill('input[type="email"]', 'admin@example.com');
    await page.fill('input[type="password"]', 'admin123456');
    await page.click('button:has-text("ã‚µã‚¤ãƒ³ã‚¤ãƒ³")');
    await page.waitForTimeout(5000);

    // Upload new audio file
    console.log('ğŸ“¤ 3. Uploading sample audio file...');
    
    // Go to upload page or find upload button
    const uploadButton = await page.$('button:has-text("éŒ²éŸ³"), button:has-text("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"), input[type="file"]');
    
    if (!uploadButton) {
      // Try to find upload via other means
      const addButton = await page.$('button:has-text("+"), [data-testid="upload-button"]');
      if (addButton) {
        await addButton.click();
        await page.waitForTimeout(2000);
      }
    }

    // Look for file input
    const fileInput = await page.$('input[type="file"]');
    if (fileInput) {
      const audioFilePath = '/Users/hashimotokenichi/Downloads/ã‚µãƒ³ãƒ—ãƒ«ä¼šè­°éŸ³å£° [Vbwl01D7Y3Y].mp3';
      console.log(`ğŸ“ Uploading file: ${audioFilePath}`);
      
      await fileInput.setInputFiles(audioFilePath);
      await page.waitForTimeout(3000);
      
      // Wait for upload completion
      console.log('â±ï¸ Waiting for upload to complete...');
      await page.waitForTimeout(10000);
      
    } else {
      console.log('âš ï¸ File input not found - testing with existing file');
      
      // Reset existing file status for testing
      console.log('ğŸ”„ Resetting file status for testing...');
      
      // Find an audio file and reset its status
      const audioCards = await page.$$('.cursor-pointer');
      if (audioCards.length > 0) {
        await audioCards[0].click();
        await page.waitForTimeout(3000);
        
        // Reset via browser console (if needed)
        await page.evaluate(() => {
          console.log('ğŸ”§ Attempting to reset file status via browser...');
        });
      }
    }

    // Find the uploaded/reset audio file
    console.log('ğŸ¯ 4. Finding audio file to process...');
    await page.goto('https://voicenote-dev.web.app');
    await page.waitForTimeout(3000);

    const audioCards = await page.$$('.cursor-pointer');
    console.log(`ğŸ“ Found ${audioCards.length} audio files`);

    if (audioCards.length > 0) {
      // Click on the first (most recent) audio file
      await audioCards[0].click();
      await page.waitForTimeout(3000);

      // Look for process button
      const processButton = await page.$('button:has-text("æ–‡å­—èµ·ã“ã—"), button:has-text("é–‹å§‹"), button:has-text("å†è©¦è¡Œ")');
      
      if (processButton) {
        console.log('ğŸš€ 5. Starting transcription with axios multipart...');
        
        // Click process button
        await processButton.click();
        
        // Monitor processing in detail
        console.log('ğŸ“Š Monitoring processing with axios...');
        
        let multipartErrorCount = 0;
        let axiosSuccessDetected = false;
        let apiSuccessDetected = false;
        
        for (let i = 0; i < 180; i++) { // 3 minutes
          await page.waitForTimeout(1000);
          
          if (i % 10 === 0) {
            console.log(`â±ï¸ ${i}s elapsed...`);
          }
          
          const bodyText = await page.textContent('body');
          
          // Check for processing status updates
          if (bodyText.includes('Firebase Functions ã§å‡¦ç†ã‚’é–‹å§‹')) {
            console.log(`ğŸ“ ${i}s: ğŸ”¥ Firebase Functions processing initiated`);
          }
          
          if (bodyText.includes('éŸ³å£°èªè­˜å‡¦ç†ä¸­')) {
            console.log(`ğŸ“ ${i}s: ğŸ¤ Speech recognition in progress`);
          }
          
          if (bodyText.includes('å®Œäº†') || bodyText.includes('completed')) {
            console.log(`ğŸ“ ${i}s: âœ… Processing completed`);
            break;
          }
          
          if (bodyText.includes('ã‚¨ãƒ©ãƒ¼')) {
            console.log(`ğŸ“ ${i}s: âŒ Error detected`);
            break;
          }
        }
        
        // Check results
        console.log('ğŸ“‹ 6. Checking transcription results...');
        
        const transcriptTab = await page.$('[role="tab"]:has-text("æ–‡å­—èµ·ã“ã—")');
        if (transcriptTab) {
          await transcriptTab.click();
          await page.waitForTimeout(2000);
          
          const transcriptContent = await page.textContent('body');
          
          if (transcriptContent.includes('ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰') || transcriptContent.includes('demo')) {
            console.log('âŒ Still showing demo content');
            console.log('   - multipart form issue may still exist');
            console.log('   - or API key authentication issue');
          } else if (transcriptContent.includes('OpenAI') && !transcriptContent.includes('ãƒ‡ãƒ¢')) {
            console.log('âœ… Real OpenAI transcription detected!');
          } else if (transcriptContent.includes('Aã•ã‚“') || transcriptContent.includes('Bã•ã‚“')) {
            console.log('âœ… Speaker labels working');
          }
          
          // Check for actual transcription content
          if (transcriptContent.length > 100 && !transcriptContent.includes('ãƒ‡ãƒ¢')) {
            console.log('âœ… Substantial transcription content found - likely real');
          }
        }
        
      } else {
        console.log('âš ï¸ Process button not found - file may already be processed');
      }
    }

    await page.screenshot({ path: 'upload-and-test-processing.png', fullPage: true });

    // Check Firebase Functions logs
    console.log('ğŸ“‹ 7. Checking Firebase Functions logs for this session...');
    
  } catch (error) {
    console.log(`ğŸ’¥ Test error: ${error.message}`);
    await page.screenshot({ path: 'upload-test-error.png', fullPage: true });
  } finally {
    await browser.close();
    console.log('âœ… Upload and test completed');
  }
}

uploadAndTestRealProcessing().catch(console.error);